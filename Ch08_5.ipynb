{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ch08-5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMTeaKGu05SligQL9G3bcRj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mimiachiu/Deep-Learning-with-Python-Book/blob/master/Ch08_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TP42k4MD-smq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "d850818d-89c9-4dc2-912c-a3e053365d2e"
      },
      "source": [
        "pip install keras"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (2.3.1)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.18.5)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.4.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras) (1.1.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras) (1.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.10.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCldHnHS-ybl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "outputId": "bf3e3345-b378-469c-bda6-cd52b626eeaa"
      },
      "source": [
        "#GAN生成器神經網路\n",
        "import keras\n",
        "from keras import layers\n",
        "import numpy as np\n",
        "\n",
        "latent_dim = 32\n",
        "height = 32\n",
        "width = 32\n",
        "channels = 3\n",
        "\n",
        "generator_input = keras.Input(shape=(latent_dim, ))\n",
        "\n",
        "x = layers.Dense(128 * 16 * 16)(generator_input)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Reshape((16, 16, 128))(x)\n",
        "print(x.shape)\n",
        "\n",
        "x = layers.Conv2D(256, 5, padding='same')(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "print(x.shape)\n",
        "\n",
        "x = layers.Conv2DTranspose(256, 4, strides=2, padding='same')(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "print(x.shape)\n",
        "\n",
        "x = layers.Conv2D(256, 5, padding='same')(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Conv2D(256, 5, padding='same')(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "\n",
        "x = layers.Conv2D(channels, 7, activation='tanh', padding='same')(x)\n",
        "generator = keras.models.Model(generator_input, x)\n",
        "generator.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, 16, 16, 128)\n",
            "(None, 16, 16, 256)\n",
            "(None, None, None, 256)\n",
            "Model: \"model_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_5 (InputLayer)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 32768)             1081344   \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_14 (LeakyReLU)   (None, 32768)             0         \n",
            "_________________________________________________________________\n",
            "reshape_2 (Reshape)          (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 16, 16, 256)       819456    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_15 (LeakyReLU)   (None, 16, 16, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_2 (Conv2DTr (None, 32, 32, 256)       1048832   \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_16 (LeakyReLU)   (None, 32, 32, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 32, 32, 256)       1638656   \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_17 (LeakyReLU)   (None, 32, 32, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_15 (Conv2D)           (None, 32, 32, 256)       1638656   \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_18 (LeakyReLU)   (None, 32, 32, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_16 (Conv2D)           (None, 32, 32, 3)         37635     \n",
            "=================================================================\n",
            "Total params: 6,264,579\n",
            "Trainable params: 6,264,579\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDG1XmiC__gX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "outputId": "18d1411b-9965-4b84-cc61-e3e807fb1826"
      },
      "source": [
        "#GAN鑑別器神經網路\n",
        "discriminator_input = layers.Input(shape=(height, width, channels))\n",
        "\n",
        "x = layers.Conv2D(128, 3)(discriminator_input)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Conv2D(128, 4, strides=2)(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Conv2D(128, 4, strides=2)(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Conv2D(128, 4, strides=2)(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "print(x.shape)\n",
        "\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dropout(0.4)(x)\n",
        "x = layers.Dense(1, activation='sigmoid')(x)\n",
        "print(x.shape)\n",
        "\n",
        "discriminator = keras.models.Model(discriminator_input, x)\n",
        "discriminator.summary()\n",
        "\n",
        "discriminator_optimizer = keras.optimizers.RMSprop(lr=0.0008, clipvalue=1.0, decay=1e-8)\n",
        "discriminator.compile(optimizer=discriminator_optimizer, loss='binary_crossentropy')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, 2, 2, 128)\n",
            "(None, 1)\n",
            "Model: \"model_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_17 (Conv2D)           (None, 30, 30, 128)       3584      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_19 (LeakyReLU)   (None, 30, 30, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_18 (Conv2D)           (None, 14, 14, 128)       262272    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_20 (LeakyReLU)   (None, 14, 14, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_19 (Conv2D)           (None, 6, 6, 128)         262272    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_21 (LeakyReLU)   (None, 6, 6, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_20 (Conv2D)           (None, 2, 2, 128)         262272    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_22 (LeakyReLU)   (None, 2, 2, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 790,913\n",
            "Trainable params: 790,913\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEYUfw1QBEps",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#對抗神經網路\n",
        "discriminator.trainable = False\n",
        "\n",
        "gan_input = keras.Input(shape=(latent_dim,))\n",
        "gan_output = discriminator(generator(gan_input))\n",
        "gan = keras.models.Model(gan_input, gan_output)\n",
        "\n",
        "gan_optimizer = keras.optimizers.RMSprop(lr=0.0004, clipvalue=1.0, decay=1e-8)\n",
        "gan.compile(optimizer=gan_optimizer, loss='binary_crossentropy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8l8PD2YBNQm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1316cbd6-548e-4442-9740-387c1f5edcee"
      },
      "source": [
        "#實作GAN訓練\n",
        "import os\n",
        "from keras.preprocessing import image\n",
        "\n",
        "(x_train, y_train), (_, _) = keras.datasets.cifar10.load_data()\n",
        "x_train = x_train[y_train.flatten() == 6] #選擇青蛙圖像(類別6)\n",
        "x_train = x_train.reshape((x_train.shape[0], ) + (height, width, channels)).astype('float32') / 255.\n",
        "\n",
        "iterations = 10000\n",
        "batch_size = 20\n",
        "save_dir = ''\n",
        "\n",
        "start = 0\n",
        "for step in range(iterations):\n",
        "    random_latent_vectors = np.random.normal(size=(batch_size, latent_dim))\n",
        "\n",
        "    generated_images = generator.predict(random_latent_vectors)\n",
        "\n",
        "    stop = start + batch_size\n",
        "    real_images = x_train[start: stop]\n",
        "    combined_images = np.concatenate([generated_images, real_images]) #將假圖片與真實圖像相混合\n",
        "\n",
        "    labels = np.concatenate([np.ones((batch_size, 1)), np.zeros((batch_size, 1))])\n",
        "    labels += 0.05 * np.random.random(labels.shape) #在標籤中增加隨機雜訊\n",
        "\n",
        "    d_loss = discriminator.train_on_batch(combined_images, labels)\n",
        "\n",
        "    random_latent_vectors = np.random.normal(size=(batch_size, latent_dim))\n",
        "    misleading_targets = np.zeros((batch_size, 1))\n",
        "\n",
        "    a_loss = gan.train_on_batch(random_latent_vectors, misleading_targets)\n",
        "\n",
        "    start += batch_size\n",
        "    if start > len(x_train) - batch_size:\n",
        "        start = 0\n",
        "    \n",
        "    if step % 100 == 0:\n",
        "        gan.save_weights('gan.h5')\n",
        "\n",
        "        print('discriminator loss at step %s: %s' % (step, d_loss))\n",
        "        print('adversarial loss at step %s: %s' % (step, a_loss))\n",
        "        #儲存一個生成的圖像\n",
        "        img = image.array_to_img(generated_images[0] * 255., scale=False)\n",
        "        img.save(os.path.join(save_dir, 'generated_frog' + str(step) + '.png'))\n",
        "        #儲存一個真實圖像以進行比較\n",
        "        img = image.array_to_img(real_images[0] * 255., scale=False)\n",
        "        img.save(os.path.join(save_dir, 'real_frog' + str(step) + '.png'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "discriminator loss at step 0: 0.68812716\n",
            "adversarial loss at step 0: 0.6767637\n",
            "discriminator loss at step 100: 0.729507\n",
            "adversarial loss at step 100: 0.73772156\n",
            "discriminator loss at step 200: 0.71115875\n",
            "adversarial loss at step 200: 0.9743029\n",
            "discriminator loss at step 300: 0.691285\n",
            "adversarial loss at step 300: 0.7647408\n",
            "discriminator loss at step 400: 0.7025089\n",
            "adversarial loss at step 400: 0.74081457\n",
            "discriminator loss at step 500: 0.69695914\n",
            "adversarial loss at step 500: 0.7586745\n",
            "discriminator loss at step 600: 0.71710217\n",
            "adversarial loss at step 600: 0.7390163\n",
            "discriminator loss at step 700: 0.7069191\n",
            "adversarial loss at step 700: 0.76956093\n",
            "discriminator loss at step 800: 0.69161975\n",
            "adversarial loss at step 800: 0.76707506\n",
            "discriminator loss at step 900: 0.6863682\n",
            "adversarial loss at step 900: 0.6762763\n",
            "discriminator loss at step 1000: 0.69502527\n",
            "adversarial loss at step 1000: 0.7724148\n",
            "discriminator loss at step 1100: 0.6904712\n",
            "adversarial loss at step 1100: 0.7486919\n",
            "discriminator loss at step 1200: 0.7027835\n",
            "adversarial loss at step 1200: 0.7365157\n",
            "discriminator loss at step 1300: 0.6923454\n",
            "adversarial loss at step 1300: 0.8141171\n",
            "discriminator loss at step 1400: 0.6893488\n",
            "adversarial loss at step 1400: 0.75409234\n",
            "discriminator loss at step 1500: 0.68611735\n",
            "adversarial loss at step 1500: 0.7137102\n",
            "discriminator loss at step 1600: 0.67386025\n",
            "adversarial loss at step 1600: 0.77970475\n",
            "discriminator loss at step 1700: 0.7440193\n",
            "adversarial loss at step 1700: 0.7687532\n",
            "discriminator loss at step 1800: 0.69130975\n",
            "adversarial loss at step 1800: 0.75621617\n",
            "discriminator loss at step 1900: 0.6993826\n",
            "adversarial loss at step 1900: 0.7621334\n",
            "discriminator loss at step 2000: 0.6968838\n",
            "adversarial loss at step 2000: 0.7179025\n",
            "discriminator loss at step 2100: 0.6975191\n",
            "adversarial loss at step 2100: 0.73402405\n",
            "discriminator loss at step 2200: 0.6860231\n",
            "adversarial loss at step 2200: 0.7676524\n",
            "discriminator loss at step 2300: 0.6820984\n",
            "adversarial loss at step 2300: 0.7070568\n",
            "discriminator loss at step 2400: 0.696361\n",
            "adversarial loss at step 2400: 0.74741185\n",
            "discriminator loss at step 2500: 0.7145909\n",
            "adversarial loss at step 2500: 0.72115946\n",
            "discriminator loss at step 2600: 0.69179094\n",
            "adversarial loss at step 2600: 0.7101136\n",
            "discriminator loss at step 2700: 0.68201965\n",
            "adversarial loss at step 2700: 0.6938783\n",
            "discriminator loss at step 2800: 0.6877536\n",
            "adversarial loss at step 2800: 0.7608556\n",
            "discriminator loss at step 2900: 0.690428\n",
            "adversarial loss at step 2900: 0.7191586\n",
            "discriminator loss at step 3000: 0.6893859\n",
            "adversarial loss at step 3000: 0.76440895\n",
            "discriminator loss at step 3100: 0.69779426\n",
            "adversarial loss at step 3100: 0.7118585\n",
            "discriminator loss at step 3200: 0.6807139\n",
            "adversarial loss at step 3200: 0.7421113\n",
            "discriminator loss at step 3300: 0.68759763\n",
            "adversarial loss at step 3300: 0.7541716\n",
            "discriminator loss at step 3400: 0.69854224\n",
            "adversarial loss at step 3400: 0.77762306\n",
            "discriminator loss at step 3500: 0.69564056\n",
            "adversarial loss at step 3500: 0.73600113\n",
            "discriminator loss at step 3600: 0.6985186\n",
            "adversarial loss at step 3600: 0.38445714\n",
            "discriminator loss at step 3700: 0.6991445\n",
            "adversarial loss at step 3700: 0.8361621\n",
            "discriminator loss at step 3800: 0.6958021\n",
            "adversarial loss at step 3800: 0.7604587\n",
            "discriminator loss at step 3900: 0.70543593\n",
            "adversarial loss at step 3900: 0.7370369\n",
            "discriminator loss at step 4000: 0.69147855\n",
            "adversarial loss at step 4000: 0.7135099\n",
            "discriminator loss at step 4100: 0.6924219\n",
            "adversarial loss at step 4100: 0.98638475\n",
            "discriminator loss at step 4200: 0.688311\n",
            "adversarial loss at step 4200: 0.73870474\n",
            "discriminator loss at step 4300: 0.6872818\n",
            "adversarial loss at step 4300: 0.6800922\n",
            "discriminator loss at step 4400: 0.6878377\n",
            "adversarial loss at step 4400: 0.7493413\n",
            "discriminator loss at step 4500: 0.70135033\n",
            "adversarial loss at step 4500: 0.7374169\n",
            "discriminator loss at step 4600: 0.6937382\n",
            "adversarial loss at step 4600: 0.7409706\n",
            "discriminator loss at step 4700: 0.69715106\n",
            "adversarial loss at step 4700: 0.99484044\n",
            "discriminator loss at step 4800: 0.6976617\n",
            "adversarial loss at step 4800: 1.3102349\n",
            "discriminator loss at step 4900: 0.6940854\n",
            "adversarial loss at step 4900: 0.7616168\n",
            "discriminator loss at step 5000: 0.6842934\n",
            "adversarial loss at step 5000: 0.72478664\n",
            "discriminator loss at step 5100: 0.69949895\n",
            "adversarial loss at step 5100: 0.77647245\n",
            "discriminator loss at step 5200: 0.69227874\n",
            "adversarial loss at step 5200: 0.7829224\n",
            "discriminator loss at step 5300: 0.69114685\n",
            "adversarial loss at step 5300: 0.7447343\n",
            "discriminator loss at step 5400: 0.70450836\n",
            "adversarial loss at step 5400: 0.7689823\n",
            "discriminator loss at step 5500: 0.69174093\n",
            "adversarial loss at step 5500: 0.736227\n",
            "discriminator loss at step 5600: 0.67307854\n",
            "adversarial loss at step 5600: 0.7419401\n",
            "discriminator loss at step 5700: 0.6978428\n",
            "adversarial loss at step 5700: 0.79278374\n",
            "discriminator loss at step 5800: 0.6955751\n",
            "adversarial loss at step 5800: 0.7956702\n",
            "discriminator loss at step 5900: 0.680899\n",
            "adversarial loss at step 5900: 0.7371977\n",
            "discriminator loss at step 6000: 0.6903066\n",
            "adversarial loss at step 6000: 0.75936115\n",
            "discriminator loss at step 6100: 0.72835124\n",
            "adversarial loss at step 6100: 0.8451564\n",
            "discriminator loss at step 6200: 0.7025519\n",
            "adversarial loss at step 6200: 0.76608\n",
            "discriminator loss at step 6300: 0.70467824\n",
            "adversarial loss at step 6300: 0.8509784\n",
            "discriminator loss at step 6400: 0.67882335\n",
            "adversarial loss at step 6400: 0.8385719\n",
            "discriminator loss at step 6500: 0.6786596\n",
            "adversarial loss at step 6500: 0.7958508\n",
            "discriminator loss at step 6600: 0.70768905\n",
            "adversarial loss at step 6600: 0.7363137\n",
            "discriminator loss at step 6700: 0.6911\n",
            "adversarial loss at step 6700: 1.1139183\n",
            "discriminator loss at step 6800: 0.67127216\n",
            "adversarial loss at step 6800: 0.77131176\n",
            "discriminator loss at step 6900: 0.72249365\n",
            "adversarial loss at step 6900: 0.81487244\n",
            "discriminator loss at step 7000: 0.6710619\n",
            "adversarial loss at step 7000: 0.7239044\n",
            "discriminator loss at step 7100: 0.6853983\n",
            "adversarial loss at step 7100: 0.77358055\n",
            "discriminator loss at step 7200: 0.6733303\n",
            "adversarial loss at step 7200: 0.78848106\n",
            "discriminator loss at step 7300: 0.701661\n",
            "adversarial loss at step 7300: 0.77868396\n",
            "discriminator loss at step 7400: 0.68223643\n",
            "adversarial loss at step 7400: 0.684144\n",
            "discriminator loss at step 7500: 0.6588466\n",
            "adversarial loss at step 7500: 0.8667525\n",
            "discriminator loss at step 7600: 0.68837476\n",
            "adversarial loss at step 7600: 0.7435907\n",
            "discriminator loss at step 7700: 0.74926203\n",
            "adversarial loss at step 7700: 0.977108\n",
            "discriminator loss at step 7800: 0.6690978\n",
            "adversarial loss at step 7800: 1.1340063\n",
            "discriminator loss at step 7900: 0.6938931\n",
            "adversarial loss at step 7900: 0.8142252\n",
            "discriminator loss at step 8000: 0.6601952\n",
            "adversarial loss at step 8000: 0.88430154\n",
            "discriminator loss at step 8100: 0.67237043\n",
            "adversarial loss at step 8100: 0.8060066\n",
            "discriminator loss at step 8200: 0.6976078\n",
            "adversarial loss at step 8200: 0.76038814\n",
            "discriminator loss at step 8300: 0.7331216\n",
            "adversarial loss at step 8300: 0.69636565\n",
            "discriminator loss at step 8400: 0.6897041\n",
            "adversarial loss at step 8400: 0.7696158\n",
            "discriminator loss at step 8500: 0.674024\n",
            "adversarial loss at step 8500: 0.84576637\n",
            "discriminator loss at step 8600: 0.68143874\n",
            "adversarial loss at step 8600: 0.78040946\n",
            "discriminator loss at step 8700: 0.6956058\n",
            "adversarial loss at step 8700: 0.75182587\n",
            "discriminator loss at step 8800: 0.6877877\n",
            "adversarial loss at step 8800: 0.8269054\n",
            "discriminator loss at step 8900: 0.6719568\n",
            "adversarial loss at step 8900: 0.81366575\n",
            "discriminator loss at step 9000: 0.6696149\n",
            "adversarial loss at step 9000: 0.8005854\n",
            "discriminator loss at step 9100: 0.7500288\n",
            "adversarial loss at step 9100: 0.7411574\n",
            "discriminator loss at step 9200: 0.6921798\n",
            "adversarial loss at step 9200: 0.72037876\n",
            "discriminator loss at step 9300: 0.6544241\n",
            "adversarial loss at step 9300: 1.0425736\n",
            "discriminator loss at step 9400: 0.71320355\n",
            "adversarial loss at step 9400: 0.7265667\n",
            "discriminator loss at step 9500: 0.6785021\n",
            "adversarial loss at step 9500: 0.83428013\n",
            "discriminator loss at step 9600: 0.6801939\n",
            "adversarial loss at step 9600: 0.7428765\n",
            "discriminator loss at step 9700: 0.73150015\n",
            "adversarial loss at step 9700: 0.84455526\n",
            "discriminator loss at step 9800: 0.8132609\n",
            "adversarial loss at step 9800: 0.94970113\n",
            "discriminator loss at step 9900: 0.6754244\n",
            "adversarial loss at step 9900: 0.68108857\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}